# fly.toml app configuration file generated for llama-farm-shepherd on 2024-05-03T22:13:26-07:00
#
# See https://fly.io/docs/reference/configuration/ for information about how to use this file.
#

app = 'llama-farm-shepherd'
primary_region = 'ord'

[build]

# [http_service]
# internal_port = 8080
# force_https = true
# auto_stop_machines = true
# auto_start_machines = true
# min_machines_running = 0
# processes = ['app']

[[vm]]
# size = "a100-40gb"
memory = '64gb'
cpu_kind = 'performance'
cpus = 16


[[mounts]]
source = "ollama"
destination = "/root/.ollama"
